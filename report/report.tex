\documentclass[onecolumn, 12pt, a4paper]{article}
\usepackage{physics}
 
\author{
  George Herbert\\
  \texttt{cj19328@bristol.ac.uk}
}

\title{An Unknown Signal Report}
\begin{document}

\maketitle

\begin{abstract}
    This report demonstrates my understanding of the methods I have 
    used, the results results I have obtained and my understanding
    of issues such as overfitting for the `An Unknown Signal'
    coursework.
\end{abstract}

\section{Equations for linear regression}

For a set of points that lie along a line with Gaussian noise 
$\vb{y} = \vb{X}\vb{w} + \vb{\epsilon}$ where $\epsilon_{i} \sim \mathcal{N}(0, \sigma^{2})$,
the maximum likelihood esimation is equivalent to the least square 
error estimation and is given by the equation:
\[
    \vb{\hat{w}} = (\vb{X^{T}}\vb{X})^{-1}\vb{X^{T}}\vb{y}.
\]
I've implemented this equation in my code as the following function:
\begin{verbatim}
def regressionNormalEquation(self, X, y):
    return np.linalg.inv(X.T @ X) @ X.T @ y
\end{verbatim}

\section{Choice of polynomial order}

\section{Choice of unknown function}

\section{Overfitting}

Overfitting occurs when an algorithm produces a model that has
learnt the noise in the data as if it represents the
structure of the underlying model.
In the case of linear regeression, overfitting typically occurs
when the model produced contains too complex a function class,
such that it would fail to predict future observations.

Cross-validation can be used to detect overfitting. We can partition
our data into two subsets: a training set and a validation set;


To prevent overfitting, I have used $k$-fold cross-validation
for each line segment, the process for which is as follows:

\begin{enumerate}
    \item Shuffle the dataset
    \item Split the dataset provided into $k$ equally sized subsamples
    \item Perform cross-validation $k$ times, using each subsample exactly once as the validation data
\end{enumerate}

\section{Procedure for determining function}

\section{Testing}









\end{document}
