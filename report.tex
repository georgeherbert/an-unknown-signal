\documentclass[onecolumn, 12pt, a4paper]{article}
\usepackage{physics}
 
\author{
  George Herbert\\
  \texttt{cj19328@bristol.ac.uk}
}

\title{An Unknown Signal Report}
\begin{document}

\maketitle

\begin{abstract}
    This report demonstrates my understanding of the methods I have 
    used, the results results I have obtained and my understanding
    of issues such as overfitting for the `An Unknown Signal'
    coursework.
\end{abstract}

\section{Equations for linear regression}

For a set of points that lie along a line with Gaussian noise 
$\vb{y} = \vb{X}\vb{w} + \vb{\epsilon}$ where $\epsilon_{i} \sim \mathcal{N}(0, \sigma^{2})$,
the maximum likelihood esimation is equivalent to the least square 
error estimation and is given by the equation:
\[
    \vb{\hat{w}} = (\vb{X^{T}}\vb{X})^{-1}\vb{X^{T}}\vb{y}.
\]

I've implemented this equation in my code as the following to calculate
the maximum likelihood estimation for my training data:
\begin{verbatim}
ws = np.linalg.inv(X.T @ X) @ X.T @ self.ysTraining.
\end{verbatim}

\section{Choice of polynomial order}

\section{Choice of unknown function}

\section{Procedure for determining function}

\section{Overfitting}

Overfitting occurs when an algorithm produces a model that has
learnt the noise in the data as if it represents the
structure of the underlying model.

In the case of linear regeression, overfitting typically occurs
when the model produced contains too complex a function class,
such that it would fail to predict future observations.


\section{Testing}









\end{document}
