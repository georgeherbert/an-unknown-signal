\documentclass[onecolumn, 12pt, a4paper]{article}
\usepackage{physics}
 
\author{
  George Herbert\\
  \texttt{cj19328@bristol.ac.uk}
}

\title{An Unknown Signal Report}
\begin{document}

\maketitle

\begin{abstract}
    This report demonstrates my understanding of the methods I have 
    used, the results results I have obtained and my understanding
    of issues such as overfitting for the `An Unknown Signal'
    coursework.
\end{abstract}

\section{Equations for linear regression}

For a set of points that lie along a line with Gaussian noise 
$\vb{y} = \vb{X}\vb{w} + \vb{\epsilon}$ where $\epsilon_{i} \sim \mathcal{N}(0, \sigma^{2})$,
the maximum likelihood esimation is equivalent to the least square 
error estimation and is given by the equation:
\[
    \vb{\hat{w}} = (\vb{X^{T}}\vb{X})^{-1}\vb{X^{T}}\vb{y}.
\]
I've implemented this equation in my code as the following function:
\begin{verbatim}
def regressionNormalEquation(self, X, y):
    return np.linalg.inv(X.T @ X) @ X.T @ y
\end{verbatim}

\section{Choice of polynomial order}

\section{Choice of unknown function}

\section{Model selection}

Overfitting occurs when an algorithm produces a model that has
learnt the noise in the data as if it represents the
structure of the underlying model.
In the case of linear regeression, overfitting typically occurs
when the model produced contains too complex a function class,
such that it would fail to predict future observations.

To prevent overfitting each line segment, I have used a type of 
cross-validation known as $k$-fold cross-validation---in particular,
I have used 5-fold cross-validation. 
I opted to use $k$-fold cross-validation due to the small number
of datapoints in each segment.

To begin with, $k$-fold cross-validation involves shuffling and 
splitting each 20-point segment into $k$ evenly-sized subsamples,
as implemented in the \texttt{getKFold()} method.
Then, each subsample is used exactly once as validation data,
whilst the other $k - 1$ paritions are used as training data.
The cross-validation error for each model is calculated
as follows \cite{EOSL}:
\[
    CV({\hat{f}}) = \frac{1}{N}\sum_{i = 1}^{N}SSE(y_{i}, \hat{f}_{i}(x_{i}))
\]
where
$\hat{f}$ is a given model;
$\hat{f}_{i}$ the fitted function, trained with the $i$-th subsample removed;
$N$ is the number of folds (in this case 5);
$SSE$ is the sum squared error function;
$y_{i}$ are the y datapoints of subsample $i$;
and $x_{i}$ are the x datapoints of subsample $i$.
The model with the lowest cross-validation error is then selected.

\section{Testing}

\begin{thebibliography}{9}
    \bibitem{EOSL} 
    Hastie, T., Tibshirani, R. and Friedman, J. (2001)
    \textit{The Elements of Statistical Learning: Data Mining, Inference, and Prediction}. 
    2nd ed. New York: Springer.
\end{thebibliography}
    

\end{document}
