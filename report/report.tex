\documentclass[onecolumn, 11pt, a4paper]{article}
\usepackage[a4paper,left = 2.5cm,right = 2.5cm, top = 2.5cm, bottom = 2.5cm]{geometry}
\usepackage{physics}
\usepackage{amsmath}
 
\author{
  George Herbert\\
  \texttt{cj19328@bristol.ac.uk}
}

\title{An Unknown Signal Report}
\begin{document}

\maketitle

\begin{abstract}
    This report demonstrates my understanding of the methods I have 
    used, the results results I have obtained and my understanding
    of issues such as overfitting for the `An Unknown Signal'
    coursework.
\end{abstract}

\section{Equations for linear regression}

For a set of points that lie along a line with Gaussian noise 
$\vb{y} = \vb{X}\vb{w} + \vb{\epsilon}$ where $\epsilon_{i} \sim \mathcal{N}(0, \sigma^{2})$,
the maximum likelihood esimation of $\vb{w}$ is equivalent to
the least square error estimation and is given by the equation:
\[
    \vb{\hat{w}} = (\vb{X}^{T}\vb{X})^{-1}\vb{X}^{T}\vb{y}.
\]
This equation is implementing in my code as the following
method:
\begin{verbatim}
def regressionNormalEquation(self, X, y):
    return np.linalg.inv(X.T @ X) @ X.T @ y
\end{verbatim}

$\vb{X}$ can take one of the following
three forms:
\[
\vb{X} =
\begin{bmatrix}
    x_{1} & 1 \\
    \vdots & \vdots \\
    x_{20} & 1 \\
\end{bmatrix}
\quad
\vb{X} =
\begin{bmatrix}
    x_{1}^{n} & x_{1}^{n-1} & \dots & 1 \\
    \vdots & \vdots & \ddots & \vdots \\
    x_{20}^{n} & x_{20}^{n-1} & \dots & 1 \\
\end{bmatrix}
\quad
\vb{X} =
\begin{bmatrix}
    f(x_{1}) & 1 \\
    \vdots & \vdots \\
    f(x_{20}) & 1 \\
\end{bmatrix}
\]
depending on whether the line is linear, polynomial of degree $n$,
or the unknown function $f$, respectively.

\section{Choice of polynomial degree}

Having identified that the files named `\texttt{basic\_*.csv}'
contained a negligable amount of noise


\section{Choice of unknown function}

Initially, I used an `eyeball estimation' to draw up a list
of candidates for the unknown function.

\section{Overfitting}

Overfitting occurs when a machine learning algorithm
produces a model that has learnt the noise in the data
as if it represents the structure of the underlying
model. \cite{MSMI}

In the case of linear regression, overfitting is most
likely to occur by producing a model with too complex a function
type, such that it would fail to predict future observations.

\section{Model selection}

To prevent overfitting, I have used leave-one-out
cross-validation when producing a model for each 20-point
line segment. Leave-one-out cross-validation is 
an extreme case of $k$-fold cross validation
such that $k = n$, where
$n$ is the number of data-points (in this case 20).
Despite being computationally expensive, I believe that
leave-one-out cross-validation is an appropriate technique
to prevent overfitting due to the limited sample size
of each line segment.

Leave-one-out cross-validation involves using each of
the 20 data-points exactly once as validation data for a model
trained using the other 19 data-points. 
The cross-validation error for each function type is calculated
as follows \cite{Stanford}:
\[
    CV_{(n)} = \frac{1}{n} \sum_{i = 1}^{n} (y_{i} - \hat{y}^{(-i)})^{2}
\]
where
$n$ is the number of datapoints in a line segment (i.e. 20);
$y_{i}$ is the actual $y$-value for the $i$-th datapoint;
and $\hat{y}^{(-i)}$ is the predicted $y$-value for the $i$-th
datapoint, when trained without using the $i$-th sample.

The function type with the lowest cross-validation error is then selected.

\section{Testing}

\section{Optimisations and improvements}

To begin with,
computing the matrix inverse using the \texttt{np.linalg.inv}
method is computationally expensive and unncessary.
Instead, given $\vb{X}$ and $\vb{y}$ the maximum likelihood
estimation could be computed directly as follows:
\texttt{np.linalg.solve(X.T @ X, @ X.T @ y)}.
This would be computationally faster, as \texttt{np.linalg.inv}
computes the inverse of a matrix $\vb{A}$ by solving for $\vb{A}^{-1}$
in $\vb{AA^{-1} = I}$ \cite{StackOverflow}.
So, you could save time and computing power by solving
for $\vb{\hat{w}}$ in
$\vb{X}^{T} \vb{X} \vb{\hat{w}} = \vb{X}^{T} \vb{y}$ directly.

Secondly, calculating the cross-validation error using leave-one-out
cross-validation is computationally expensive, as it involves
fitting the model and calculating the sum squared error
$n$ times. I could have used a less
computationally-expensive way of calculating the cross-validation
error that involves calculating the leverage.
However, I opted not to do this as my algorithm as it
currently stands can be easily adapted to use $k$-fold
cross-validation for any value of $k$ that is a factor of 20
by changing the constant \texttt{K} in my code.


\begin{enumerate}
    \item{Not shuffling the data before leave-one-out cross-validation}
    \item{Not finding the average cross-validation error}
    \item{Using the linear regression leave-one-out shortcut}
\end{enumerate}

\begin{thebibliography}{9}

    \bibitem{MSMI}
    Burnham, K. P. and Anderson, D. R. (2002)
    \textit{Model Selection and Multimodel Inference}.
    2nd ed. Springer-Verlag.

    \bibitem{Stanford}
    Taylor, J. (2020)
    \textit{Leave one out cross-validation (LOOCV) --- STATS 202}
    https://web.stanford.edu/class/stats202/notes/Resampling/LOOCV.html

    \bibitem{StackOverflow}
    Muldal, A. (2017)
    \textit{Why does numpy.linalg.solve() offer more precise matrix inversions than numpy.linalg.inv()?}
    https://stackoverflow.com/a/31257909/8540479



\end{thebibliography}
    

\end{document}
