\documentclass[onecolumn, 12t, a4paper]{article}
\usepackage{physics}
 
\author{
  George Herbert\\
  \texttt{cj19328@bristol.ac.uk}
}

\title{An Unknown Signal Report}
\begin{document}

\maketitle

\begin{abstract}
    This report demonstrates my understanding of the methods I have 
    used, the results results I have obtained and my understanding
    of issues such as overfitting for the `An Unknown Signal'
    coursework.
\end{abstract}

\section{Equations for linear regression}

For a set of points that lie along a line with Gaussian noise 
$\vb{y} = \vb{X}\vb{w} + \vb{\epsilon}$ where $\epsilon_{i} \sim \mathcal{N}(0, \sigma^{2})$,
the maximum likelihood esimation is equivalent to the least square 
error estimation and is given by the equation:
\[
    \vb{\hat{w}} = (\vb{X}^{T}\vb{X})^{-1}\vb{X}^{T}\vb{y}.
\]
I've implemented this equation in my code as the following function:
\begin{verbatim}
def regressionNormalEquation(self, X, y):
    return np.linalg.inv(X.T @ X) @ X.T @ y
\end{verbatim}

\section{Choice of polynomial order}

\section{Choice of unknown function}

\section{Overfitting}

Overfitting occurs when a machine learning algorithm
produces a model that has learnt the noise in the data
as if it represents the structure of the underlying
model. \cite{MSMI}

In the case of linear regression, overfitting is most
likely to occur by producing a model with too complex a function
type, such that it would fail to predict future observations.

\section{Model selection}

To prevent overfitting, I have used leave-one-out
cross-validation when producing a model for each 20-point
line segment. Leave-one-out cross-validation is 
an extreme case of $k$-fold cross validation
such that $k = n$, where
$n$ is the number of data-points (in this case 20).
Despite being computationally expensive, I believe that
leave-one-out cross-validation is an appropriate technique
to prevent overfitting, due to the limited sample size
of each line segment.

Leave-one-out cross-validation involves using each of
the 20 data-points exactly once as validation data for a model
trained using the other 19 data-points. 
The cross-validation error for each function type is calculated
as follows \cite{Stanford}:
\[
    CV_{(n)} = \frac{1}{n} \sum_{i = 1}^{n} (y_{i} - \hat{y}^{(-i)})^{2}
\]
where
$n$ is the number of datapoints in a line segment (i.e. 20);
$y_{i}$ is the actual $y$-value for the $i$-th datapoint;
and $\hat{y}^{(-i)}$ is the predicted $y$-value for the $i$-th
datapoint, when trained without using the $i$-th sample.

The function type with the lowest cross-validation error is then selected.

\section{Testing}

\section{Optimisations and improvements}

\begin{enumerate}
    \item{Using \texttt{np.linalg.solve}}
    \item{Not shuffling the data before leave-one-out cross-validation}
    \item{Not finding the average cross-validation error}
    \item{Using the linear regression leave-one-out shortcut}
\end{enumerate}

\begin{thebibliography}{9}

    \bibitem{MSMI}
    Burnham, K. P. and Anderson, D. R. (2002)
    \textit{Model Selection and Multimodel Inference}.
    2nd ed. Springer-Verlag.

    \bibitem{Stanford}
    Taylor, J. (2020)
    \textit{Leave one out cross-validation (LOOCV)}
    https://web.stanford.edu/class/stats202/notes/Resampling/LOOCV.html

\end{thebibliography}
    

\end{document}
